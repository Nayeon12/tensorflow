{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, Tensorflow!'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "hello = tf.constant('Hello, Tensorflow!')\n",
    "\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "11493376/11490434 [==============================] - 11s 1us/step\n",
      "WARNING:tensorflow:From C:\\Users\\mycom\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 79us/sample - loss: 0.2952 - acc: 0.9137\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 5s 77us/sample - loss: 0.1419 - acc: 0.9586\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.1068 - acc: 0.9683\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 68us/sample - loss: 0.0878 - acc: 0.9730\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 71us/sample - loss: 0.0753 - acc: 0.9765\n",
      "10000/10000 - 0s - loss: 0.0728 - acc: 0.9781\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.07281825139010326, 0.9781]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "# 모델 학습시 훈련 데이터셋, 모델 예측 정확도 평가시 테스트 데이터셋\n",
    "# 모델의 출력이 y_train에 있는 대응하는 숫자가 되도록 모델을 학습\n",
    "# x_test 를 입력으로 제공시 y_test 가 출력되는지로 모델 평가\n",
    "\n",
    "x_train, x_test = x_train/255.0, x_test/255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape = (28, 28)), # 크기 28 x 28 의 배열을 입력으로 받아 1차원 배열로 변환\n",
    "    tf.keras.layers.Dense(128, activation = 'relu'), # 히든레이어의 노드개수는 128개, 활성화 함수로 relu 사용\n",
    "    tf.keras.layers.Dropout(0.2), # 오버피팅 방지, 이전레이어의 출력을 20% 끈다\n",
    "    tf.keras.layers.Dense(10, activation = 'softmax') # 출력레이어의 노드개수는 10개, 활성화 함수는 softmax\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    optimizer = 'adam',\n",
    "    loss = 'sparse_categorical_crossentropy', # 손실함수로 크로스 엔트로피\n",
    "    metrics = ['accuracy'] # 메트릭은 모델을 평가할때 사용 , 정확도\n",
    ")\n",
    "\n",
    "model.fit(x_train, y_train, epochs = 5) # 모델 5번 반복 훈련\n",
    "model.evaluate(x_test, y_test, verbose = 2) # 테스트 데이터셋으로 모델 평가\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
